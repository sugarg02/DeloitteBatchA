{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFUS0gAjXWOH"
      },
      "source": [
        "# EDA Car Data Set\n",
        "\n",
        "**We will explore the Car Data set and perform the exploratory data analysis on the dataset. The major topics to be covered are below:**\n",
        "\n",
        "- **Removing duplicates**\n",
        "- **Missing value treatment**\n",
        "- **Outlier Treatment**\n",
        "- **Normalization and Scaling( Numerical Variables)**\n",
        "- **Encoding Categorical variables( Dummy Variables)**\n",
        "- **Univerate Analysis**\n",
        "- **Bivariate Analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYkBw8GRXWOK"
      },
      "source": [
        "**As a first step, we will import all the necessary libraries that we think we will requiring to perform the EDA.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7V-CYW1XWOM"
      },
      "source": [
        "# Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-08T17:42:55.107577Z",
          "start_time": "2020-04-08T17:42:55.102597Z"
        },
        "id": "FxXjFPKaXWOM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pl-JsiTCXWOO"
      },
      "source": [
        "# Loading the data set\n",
        "\n",
        "**We will  be loading the EDA cars excel file using pandas. For this we will be using read_excel file.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-08T17:42:58.631162Z",
          "start_time": "2020-04-08T17:42:57.530483Z"
        },
        "id": "oBXlXR5fXWOO"
      },
      "outputs": [],
      "source": [
        "df=pd.read_excel('EDA Cars.xlsx')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScTO-tq5XWOP"
      },
      "source": [
        "# Basic Data Exploration \n",
        "\n",
        "**In this step, we will perform the below operations to check what the data set comprises of. We will check the below things:**\n",
        "\n",
        "- **head of the dataset**\n",
        "- **shape of the dataset**\n",
        "- **info of the dataset**\n",
        "- **summary of the dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IdvKO2UXWOR"
      },
      "source": [
        "**head function will tell you the top records in the data set. By default python shows you only top 5 records.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-s9yxicXWOS"
      },
      "source": [
        "**Shape attribute tells us number of observations and variables we have in the data set. It is used to check the dimension of data. The cars data set has 303 observations and 13 variables in the data set.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78YtEuB2XWOT"
      },
      "outputs": [],
      "source": [
        "df[\"POSTAL CODE\"]= pd.Categorical(df['POSTAL CODE']) # Converting Postel Code into Category "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7pfZ5NtXWOU"
      },
      "source": [
        "**info() is used to check the Information about the data and the datatypes of each respective attributes.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iNAmTJTXWOV"
      },
      "source": [
        "**The describe method will help to see how data has been spread for the numerical values. We can clearly see the minimum value, mean values, different percentile values and maximum values.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lshngQgXWOV"
      },
      "source": [
        "# Check for Duplicate records"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jW72mWvGXWOW"
      },
      "source": [
        "**Since we have 14 duplicate records in the data, we will remove this from the data set so that we get only distinct records.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_M8xr0cXXWOW"
      },
      "source": [
        "**Post removing the duplicate, we will check whether the duplicates has been removed from the data set or not.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7w8nWkvaXWOX"
      },
      "source": [
        "**Now, we can  clearly see that there are no duplicate records in the data set. We can also quickly confirm the number of records by using the shape attribute as those 14 records should be removed from the original data. Initially it had 303 records now it should have 289**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhkYJ3daXWOX"
      },
      "source": [
        "# Outlier Treatment\n",
        "\n",
        "**To check for outliers, we will be plotting the box plots.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-08T17:43:09.015194Z",
          "start_time": "2020-04-08T17:43:08.445798Z"
        },
        "id": "6VYqykZ8XWOX"
      },
      "outputs": [],
      "source": [
        "df.boxplot(column=['INCOME'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-08T17:43:09.220949Z",
          "start_time": "2020-04-08T17:43:09.126393Z"
        },
        "scrolled": true,
        "id": "_BJiOlf7XWOY"
      },
      "outputs": [],
      "source": [
        "df.boxplot(column=['TRAVEL TIME'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-08T17:43:09.619602Z",
          "start_time": "2020-04-08T17:43:09.518443Z"
        },
        "id": "MQMsRlO_XWOY"
      },
      "outputs": [],
      "source": [
        "df.boxplot(column=['CAR AGE'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-08T17:43:10.152434Z",
          "start_time": "2020-04-08T17:43:10.052701Z"
        },
        "id": "olH2O5ooXWOY"
      },
      "outputs": [],
      "source": [
        "df.boxplot(column=['MILES CLOCKED'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4eBZjLkXWOY"
      },
      "source": [
        "**Looking at the box plot, it seems that the three variables INCOME, MILES CLOCKED and TRAVEL TIME have outlier present in the variables.**\n",
        "\n",
        "**These outliers value needs to be teated and there are several ways of treating them:**\n",
        "    \n",
        "- **Drop the outlier value**\n",
        "- **Replace the outlier value using the IQR**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5U_fvQDeXWOY"
      },
      "source": [
        "**Created a user definded function for finding the lower and upper range for a variable so that outlier can be treated.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TL9r2HWhXWOZ"
      },
      "source": [
        "##  Make Boxplots after Outlier Treatment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tolLqIGPXWOa"
      },
      "source": [
        "**If you look at the box plots above,post treating the outlier there are no outliers in all these columns.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1519P3-XWOa"
      },
      "source": [
        "# Check for missing value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBSEbjKaXWOa"
      },
      "source": [
        "**We can see that we have various missing values in respective columns. There are various ways of treating your missing values in the data set. And which technique to use when is actually dependent on the type of data you are dealing with.**\n",
        "\n",
        "- **Drop the missing values : In this case we drop the missing values from those variables. In case there are very few missing values you can drop those values.**\n",
        "\n",
        "- **Impute with mean value : For numerical column, you can replace the missing values with mean values. Before replacing with mean value, it is advisable to check that the variable shouldn't have extreme values .i.e. outliers.**\n",
        "\n",
        "- **Impute with median value : For numerical column, you can also replace the missing values with median values. In case you have extreme values such as outliers it is advisable to use median approach.**\n",
        "\n",
        "- **Impute with mode value : For categorical column, you can replace the missing values with mode values i.e the frequent ones.**\n",
        "\n",
        "**In this exercise, we will replace the numerical columns with median values and for categorical columns we will replace the missing values with mode values.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wgvef75wXWOb"
      },
      "source": [
        "**Replacing NULL values in Numerical Columns using Median**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NP0GUEsKXWOb"
      },
      "source": [
        "**Replacing NULL values in Categorical Columns using Mode**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-08T17:43:19.990388Z",
          "start_time": "2020-04-08T17:43:19.979378Z"
        },
        "id": "Yf4cNoOVXWOb"
      },
      "outputs": [],
      "source": [
        "# Check for missing value in any column\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srjqBY_tXWOc"
      },
      "source": [
        "# Univariate Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmiF37p-XWOc"
      },
      "source": [
        "From above figure, we can say that the Income parameter is right skewed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bNOmZjBXWOc"
      },
      "source": [
        "From the above graph we can interpret that majority of the people are High School passouts and this is true for both Males and Females"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flbxY4RpXWOc"
      },
      "source": [
        "# Bivariate Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gorMQxdpXWOc"
      },
      "source": [
        "**In the above plot scatter diagrams are plotted for all the numerical columns in the dataset. A scatter plot is a visual representation of the degree of correlation between any two columns. The pair plot function in seaborn makes it very easy to generate joint scatter plots for all the columns in the data.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCNmHIxAXWOd"
      },
      "source": [
        "## Correlation Heatmap"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEj6YKtHXWOd"
      },
      "source": [
        "# Normalizing and Scaling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3pDG5mCXWOd"
      },
      "source": [
        "**Often the variables of the data set are of different scales i.e. one variable is in millions and other in only 100. For e.g. in our data set Income is having values in thousands and age in just two digits. Since the data in these variables are of different scales, it is tough to compare these variables.**\n",
        "\n",
        "**Feature scaling (also known as data normalization) is the method used to standardize the range of features of data. Since, the range of values of data may vary widely, it becomes a necessary step in data preprocessing while using machine learning algorithms.**\n",
        "\n",
        "**In this method, we convert variables with different scales of measurements into a single scale.**\n",
        "\n",
        "**StandardScaler normalizes the data using the formula (x-mean)/standard deviation.**\n",
        "\n",
        "**We will be doing this only for the numerical variables.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9RZgnUmXWOe"
      },
      "source": [
        "**If you look at the variables INCOME, TRAVEL TIME and CAR AGE, all has been normalized and scaled in one scale now.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5z9OgjZXWOe"
      },
      "source": [
        "# ENCODING\n",
        "\n",
        "**One-Hot-Encoding is used to create dummy variables to replace the categories in a categorical variable into features of each category and represent it using 1 or 0 based on the presence or absence of the categorical value in the record.**\n",
        "\n",
        "**This is required to do since the machine learning algorithms only works on the numerical data. That is why there is a need to convert the categorical column into numerical one.**\n",
        "\n",
        "**get_dummies is the method which creates dummy variable for each categorical variable.**\n",
        "\n",
        "**It is considered a good practice to set parameter `drop_first` as `True` whenever get_dummies is used. It reduces the chances of multicollinearity which will be covered in coming courses and the number of features are also less as compared to `drop_first=False`**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_U7trEbZXWOf"
      },
      "source": [
        "**In the data set, each Category in all of the categorical columns have been added as columns with values 0 and 1**\n",
        "**Example: married_Yes, sex_M, Education_High School\n",
        "**If sex_M =1, then it means its a Male and sex_M=0 means its a Female**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "EDA.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}